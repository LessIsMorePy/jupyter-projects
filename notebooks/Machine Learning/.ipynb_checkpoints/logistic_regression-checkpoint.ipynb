{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../datasets/diabetes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0            6      148         72       35        0  33.6  0.627   50   \n",
       "1            1       85         66       29        0  26.6  0.351   31   \n",
       "2            8      183         64        0        0  23.3  0.672   32   \n",
       "3            1       89         66       23       94  28.1  0.167   21   \n",
       "4            0      137         40       35      168  43.1  2.288   33   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('diabetes', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age\n",
       "0            6      148         72       35        0  33.6  0.627   50\n",
       "1            1       85         66       29        0  26.6  0.351   31\n",
       "2            8      183         64        0        0  23.3  0.672   32\n",
       "3            1       89         66       23       94  28.1  0.167   21\n",
       "4            0      137         40       35      168  43.1  2.288   33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[174  32]\n",
      " [ 36  66]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.84      0.84       206\n",
      "          1       0.67      0.65      0.66       102\n",
      "\n",
      "avg / total       0.78      0.78      0.78       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification reports and confusion matrices are great methods to quantitatively evaluate model performance, while ROC curves provide a way to visually evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.61760456,  0.38239544],\n",
       "       [ 0.77666437,  0.22333563],\n",
       "       [ 0.78202778,  0.21797222],\n",
       "       [ 0.75147717,  0.24852283],\n",
       "       [ 0.54380739,  0.45619261],\n",
       "       [ 0.5352928 ,  0.4647072 ],\n",
       "       [ 0.93077363,  0.06922637],\n",
       "       [ 0.29788366,  0.70211634],\n",
       "       [ 0.48672179,  0.51327821],\n",
       "       [ 0.32587177,  0.67412823],\n",
       "       [ 0.66635194,  0.33364806],\n",
       "       [ 0.26491663,  0.73508337],\n",
       "       [ 0.5133914 ,  0.4866086 ],\n",
       "       [ 0.67306851,  0.32693149],\n",
       "       [ 0.85095436,  0.14904564],\n",
       "       [ 0.59191384,  0.40808616],\n",
       "       [ 0.8126821 ,  0.1873179 ],\n",
       "       [ 0.84409797,  0.15590203],\n",
       "       [ 0.1269536 ,  0.8730464 ],\n",
       "       [ 0.48005519,  0.51994481],\n",
       "       [ 0.70675031,  0.29324969],\n",
       "       [ 0.86992461,  0.13007539],\n",
       "       [ 0.51232461,  0.48767539],\n",
       "       [ 0.82638115,  0.17361885],\n",
       "       [ 0.45132098,  0.54867902],\n",
       "       [ 0.25959259,  0.74040741],\n",
       "       [ 0.78209407,  0.21790593],\n",
       "       [ 0.91471099,  0.08528901],\n",
       "       [ 0.72778956,  0.27221044],\n",
       "       [ 0.80934065,  0.19065935],\n",
       "       [ 0.26765248,  0.73234752],\n",
       "       [ 0.2556806 ,  0.7443194 ],\n",
       "       [ 0.30444098,  0.69555902],\n",
       "       [ 0.17378926,  0.82621074],\n",
       "       [ 0.52370169,  0.47629831],\n",
       "       [ 0.37909123,  0.62090877],\n",
       "       [ 0.21007717,  0.78992283],\n",
       "       [ 0.79502585,  0.20497415],\n",
       "       [ 0.49255756,  0.50744244],\n",
       "       [ 0.22473208,  0.77526792],\n",
       "       [ 0.84005385,  0.15994615],\n",
       "       [ 0.45132635,  0.54867365],\n",
       "       [ 0.52312641,  0.47687359],\n",
       "       [ 0.55776274,  0.44223726],\n",
       "       [ 0.91873949,  0.08126051],\n",
       "       [ 0.51558391,  0.48441609],\n",
       "       [ 0.48407102,  0.51592898],\n",
       "       [ 0.73883937,  0.26116063],\n",
       "       [ 0.59744919,  0.40255081],\n",
       "       [ 0.14662699,  0.85337301],\n",
       "       [ 0.88011342,  0.11988658],\n",
       "       [ 0.42710879,  0.57289121],\n",
       "       [ 0.24306258,  0.75693742],\n",
       "       [ 0.68725404,  0.31274596],\n",
       "       [ 0.78579614,  0.21420386],\n",
       "       [ 0.89897585,  0.10102415],\n",
       "       [ 0.30604566,  0.69395434],\n",
       "       [ 0.93498539,  0.06501461],\n",
       "       [ 0.61632496,  0.38367504],\n",
       "       [ 0.2962516 ,  0.7037484 ],\n",
       "       [ 0.38579366,  0.61420634],\n",
       "       [ 0.65669544,  0.34330456],\n",
       "       [ 0.6780249 ,  0.3219751 ],\n",
       "       [ 0.59006448,  0.40993552],\n",
       "       [ 0.86888793,  0.13111207],\n",
       "       [ 0.57885221,  0.42114779],\n",
       "       [ 0.88289474,  0.11710526],\n",
       "       [ 0.41560314,  0.58439686],\n",
       "       [ 0.91067506,  0.08932494],\n",
       "       [ 0.28186456,  0.71813544],\n",
       "       [ 0.33151993,  0.66848007],\n",
       "       [ 0.87913847,  0.12086153],\n",
       "       [ 0.69910148,  0.30089852],\n",
       "       [ 0.84721244,  0.15278756],\n",
       "       [ 0.79685358,  0.20314642],\n",
       "       [ 0.65488334,  0.34511666],\n",
       "       [ 0.77727039,  0.22272961],\n",
       "       [ 0.78654646,  0.21345354],\n",
       "       [ 0.78285021,  0.21714979],\n",
       "       [ 0.720957  ,  0.279043  ],\n",
       "       [ 0.36333322,  0.63666678],\n",
       "       [ 0.80375132,  0.19624868],\n",
       "       [ 0.87011468,  0.12988532],\n",
       "       [ 0.69085239,  0.30914761],\n",
       "       [ 0.68942805,  0.31057195],\n",
       "       [ 0.24036683,  0.75963317],\n",
       "       [ 0.26139754,  0.73860246],\n",
       "       [ 0.64201976,  0.35798024],\n",
       "       [ 0.81210273,  0.18789727],\n",
       "       [ 0.81797413,  0.18202587],\n",
       "       [ 0.86181061,  0.13818939],\n",
       "       [ 0.69812226,  0.30187774],\n",
       "       [ 0.94751115,  0.05248885],\n",
       "       [ 0.28023586,  0.71976414],\n",
       "       [ 0.45865125,  0.54134875],\n",
       "       [ 0.53313849,  0.46686151],\n",
       "       [ 0.5114928 ,  0.4885072 ],\n",
       "       [ 0.80517867,  0.19482133],\n",
       "       [ 0.34626044,  0.65373956],\n",
       "       [ 0.83119697,  0.16880303],\n",
       "       [ 0.45911141,  0.54088859],\n",
       "       [ 0.90242125,  0.09757875],\n",
       "       [ 0.29811891,  0.70188109],\n",
       "       [ 0.52138315,  0.47861685],\n",
       "       [ 0.43577847,  0.56422153],\n",
       "       [ 0.75288196,  0.24711804],\n",
       "       [ 0.67647579,  0.32352421],\n",
       "       [ 0.38934866,  0.61065134],\n",
       "       [ 0.84332938,  0.15667062],\n",
       "       [ 0.57304324,  0.42695676],\n",
       "       [ 0.8191315 ,  0.1808685 ],\n",
       "       [ 0.66136713,  0.33863287],\n",
       "       [ 0.84945741,  0.15054259],\n",
       "       [ 0.3905925 ,  0.6094075 ],\n",
       "       [ 0.75346844,  0.24653156],\n",
       "       [ 0.66199976,  0.33800024],\n",
       "       [ 0.3451373 ,  0.6548627 ],\n",
       "       [ 0.68918946,  0.31081054],\n",
       "       [ 0.85089427,  0.14910573],\n",
       "       [ 0.24575362,  0.75424638],\n",
       "       [ 0.84957575,  0.15042425],\n",
       "       [ 0.72791148,  0.27208852],\n",
       "       [ 0.71565681,  0.28434319],\n",
       "       [ 0.86025689,  0.13974311],\n",
       "       [ 0.64363597,  0.35636403],\n",
       "       [ 0.55971508,  0.44028492],\n",
       "       [ 0.76213753,  0.23786247],\n",
       "       [ 0.22766979,  0.77233021],\n",
       "       [ 0.04211905,  0.95788095],\n",
       "       [ 0.49982276,  0.50017724],\n",
       "       [ 0.32541857,  0.67458143],\n",
       "       [ 0.19728846,  0.80271154],\n",
       "       [ 0.80480688,  0.19519312],\n",
       "       [ 0.55029598,  0.44970402],\n",
       "       [ 0.31450881,  0.68549119],\n",
       "       [ 0.79918368,  0.20081632],\n",
       "       [ 0.74721166,  0.25278834],\n",
       "       [ 0.26463521,  0.73536479],\n",
       "       [ 0.31220683,  0.68779317],\n",
       "       [ 0.94546014,  0.05453986],\n",
       "       [ 0.83589586,  0.16410414],\n",
       "       [ 0.8806219 ,  0.1193781 ],\n",
       "       [ 0.72118883,  0.27881117],\n",
       "       [ 0.49569423,  0.50430577],\n",
       "       [ 0.78206594,  0.21793406],\n",
       "       [ 0.68369204,  0.31630796],\n",
       "       [ 0.81665242,  0.18334758],\n",
       "       [ 0.91919982,  0.08080018],\n",
       "       [ 0.63700627,  0.36299373],\n",
       "       [ 0.33226539,  0.66773461],\n",
       "       [ 0.82483607,  0.17516393],\n",
       "       [ 0.50377226,  0.49622774],\n",
       "       [ 0.65201626,  0.34798374],\n",
       "       [ 0.74978901,  0.25021099],\n",
       "       [ 0.93327941,  0.06672059],\n",
       "       [ 0.59786531,  0.40213469],\n",
       "       [ 0.59799327,  0.40200673],\n",
       "       [ 0.39651695,  0.60348305],\n",
       "       [ 0.31671667,  0.68328333],\n",
       "       [ 0.77523985,  0.22476015],\n",
       "       [ 0.30661577,  0.69338423],\n",
       "       [ 0.35624894,  0.64375106],\n",
       "       [ 0.74094858,  0.25905142],\n",
       "       [ 0.92868247,  0.07131753],\n",
       "       [ 0.80297016,  0.19702984],\n",
       "       [ 0.23476815,  0.76523185],\n",
       "       [ 0.88966496,  0.11033504],\n",
       "       [ 0.68497919,  0.31502081],\n",
       "       [ 0.29616157,  0.70383843],\n",
       "       [ 0.40844074,  0.59155926],\n",
       "       [ 0.38616494,  0.61383506],\n",
       "       [ 0.75316385,  0.24683615],\n",
       "       [ 0.58756799,  0.41243201],\n",
       "       [ 0.42847384,  0.57152616],\n",
       "       [ 0.39313013,  0.60686987],\n",
       "       [ 0.86669742,  0.13330258],\n",
       "       [ 0.62273368,  0.37726632],\n",
       "       [ 0.66329134,  0.33670866],\n",
       "       [ 0.69126988,  0.30873012],\n",
       "       [ 0.71314573,  0.28685427],\n",
       "       [ 0.45325767,  0.54674233],\n",
       "       [ 0.51325802,  0.48674198],\n",
       "       [ 0.56232023,  0.43767977],\n",
       "       [ 0.4618966 ,  0.5381034 ],\n",
       "       [ 0.48374467,  0.51625533],\n",
       "       [ 0.85052281,  0.14947719],\n",
       "       [ 0.89604199,  0.10395801],\n",
       "       [ 0.79565527,  0.20434473],\n",
       "       [ 0.2625871 ,  0.7374129 ],\n",
       "       [ 0.59324345,  0.40675655],\n",
       "       [ 0.83683543,  0.16316457],\n",
       "       [ 0.83003885,  0.16996115],\n",
       "       [ 0.09687468,  0.90312532],\n",
       "       [ 0.68293151,  0.31706849],\n",
       "       [ 0.87550891,  0.12449109],\n",
       "       [ 0.87680198,  0.12319802],\n",
       "       [ 0.97871931,  0.02128069],\n",
       "       [ 0.83039215,  0.16960785],\n",
       "       [ 0.71862913,  0.28137087],\n",
       "       [ 0.37023941,  0.62976059],\n",
       "       [ 0.73596212,  0.26403788],\n",
       "       [ 0.84434017,  0.15565983],\n",
       "       [ 0.65251271,  0.34748729],\n",
       "       [ 0.63719739,  0.36280261],\n",
       "       [ 0.40345255,  0.59654745],\n",
       "       [ 0.84294214,  0.15705786],\n",
       "       [ 0.81169855,  0.18830145],\n",
       "       [ 0.77922022,  0.22077978],\n",
       "       [ 0.17260589,  0.82739411],\n",
       "       [ 0.44390474,  0.55609526],\n",
       "       [ 0.67519631,  0.32480369],\n",
       "       [ 0.74195945,  0.25804055],\n",
       "       [ 0.76545625,  0.23454375],\n",
       "       [ 0.80887281,  0.19112719],\n",
       "       [ 0.37062744,  0.62937256],\n",
       "       [ 0.81554382,  0.18445618],\n",
       "       [ 0.29202439,  0.70797561],\n",
       "       [ 0.6234799 ,  0.3765201 ],\n",
       "       [ 0.64575732,  0.35424268],\n",
       "       [ 0.1905754 ,  0.8094246 ],\n",
       "       [ 0.4605474 ,  0.5394526 ],\n",
       "       [ 0.81468668,  0.18531332],\n",
       "       [ 0.82648718,  0.17351282],\n",
       "       [ 0.78656551,  0.21343449],\n",
       "       [ 0.80954005,  0.19045995],\n",
       "       [ 0.2037115 ,  0.7962885 ],\n",
       "       [ 0.4562022 ,  0.5437978 ],\n",
       "       [ 0.68287677,  0.31712323],\n",
       "       [ 0.70671596,  0.29328404],\n",
       "       [ 0.72823244,  0.27176756],\n",
       "       [ 0.84194416,  0.15805584],\n",
       "       [ 0.88767858,  0.11232142],\n",
       "       [ 0.6908049 ,  0.3091951 ],\n",
       "       [ 0.54662698,  0.45337302],\n",
       "       [ 0.61291023,  0.38708977],\n",
       "       [ 0.48282764,  0.51717236],\n",
       "       [ 0.80445603,  0.19554397],\n",
       "       [ 0.70864952,  0.29135048],\n",
       "       [ 0.6370358 ,  0.3629642 ],\n",
       "       [ 0.25258699,  0.74741301],\n",
       "       [ 0.81869371,  0.18130629],\n",
       "       [ 0.8934105 ,  0.1065895 ],\n",
       "       [ 0.4653158 ,  0.5346842 ],\n",
       "       [ 0.79419917,  0.20580083],\n",
       "       [ 0.73852274,  0.26147726],\n",
       "       [ 0.67676427,  0.32323573],\n",
       "       [ 0.32625481,  0.67374519],\n",
       "       [ 0.77884091,  0.22115909],\n",
       "       [ 0.59583691,  0.40416309],\n",
       "       [ 0.74051516,  0.25948484],\n",
       "       [ 0.78609431,  0.21390569],\n",
       "       [ 0.98592961,  0.01407039],\n",
       "       [ 0.35066741,  0.64933259],\n",
       "       [ 0.83727062,  0.16272938],\n",
       "       [ 0.75208366,  0.24791634],\n",
       "       [ 0.34044171,  0.65955829],\n",
       "       [ 0.7853381 ,  0.2146619 ],\n",
       "       [ 0.57557649,  0.42442351],\n",
       "       [ 0.81157949,  0.18842051],\n",
       "       [ 0.85286517,  0.14713483],\n",
       "       [ 0.49183045,  0.50816955],\n",
       "       [ 0.64194052,  0.35805948],\n",
       "       [ 0.77243641,  0.22756359],\n",
       "       [ 0.90271458,  0.09728542],\n",
       "       [ 0.70375345,  0.29624655],\n",
       "       [ 0.83278828,  0.16721172],\n",
       "       [ 0.49655969,  0.50344031],\n",
       "       [ 0.71550513,  0.28449487],\n",
       "       [ 0.90154694,  0.09845306],\n",
       "       [ 0.66624047,  0.33375953],\n",
       "       [ 0.5511063 ,  0.4488937 ],\n",
       "       [ 0.71227614,  0.28772386],\n",
       "       [ 0.3119568 ,  0.6880432 ],\n",
       "       [ 0.3830119 ,  0.6169881 ],\n",
       "       [ 0.61139214,  0.38860786],\n",
       "       [ 0.80804298,  0.19195702],\n",
       "       [ 0.85463538,  0.14536462],\n",
       "       [ 0.46775983,  0.53224017],\n",
       "       [ 0.77461584,  0.22538416],\n",
       "       [ 0.73406793,  0.26593207],\n",
       "       [ 0.57246245,  0.42753755],\n",
       "       [ 0.42179021,  0.57820979],\n",
       "       [ 0.20813322,  0.79186678],\n",
       "       [ 0.17434858,  0.82565142],\n",
       "       [ 0.81816552,  0.18183448],\n",
       "       [ 0.6436936 ,  0.3563064 ],\n",
       "       [ 0.24299983,  0.75700017],\n",
       "       [ 0.38523303,  0.61476697],\n",
       "       [ 0.91397731,  0.08602269],\n",
       "       [ 0.27134796,  0.72865204],\n",
       "       [ 0.79535276,  0.20464724],\n",
       "       [ 0.63242193,  0.36757807],\n",
       "       [ 0.37145278,  0.62854722],\n",
       "       [ 0.74975598,  0.25024402],\n",
       "       [ 0.66172149,  0.33827851],\n",
       "       [ 0.80334399,  0.19665601],\n",
       "       [ 0.78858035,  0.21141965],\n",
       "       [ 0.43545617,  0.56454383],\n",
       "       [ 0.40997464,  0.59002536],\n",
       "       [ 0.67729724,  0.32270276],\n",
       "       [ 0.72202174,  0.27797826],\n",
       "       [ 0.42574056,  0.57425944],\n",
       "       [ 0.27508529,  0.72491471],\n",
       "       [ 0.90912649,  0.09087351],\n",
       "       [ 0.86021095,  0.13978905],\n",
       "       [ 0.82331107,  0.17668893],\n",
       "       [ 0.98010732,  0.01989268],\n",
       "       [ 0.33374635,  0.66625365]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38239544,  0.22333563,  0.21797222,  0.24852283,  0.45619261,\n",
       "        0.4647072 ,  0.06922637,  0.70211634,  0.51327821,  0.67412823,\n",
       "        0.33364806,  0.73508337,  0.4866086 ,  0.32693149,  0.14904564,\n",
       "        0.40808616,  0.1873179 ,  0.15590203,  0.8730464 ,  0.51994481,\n",
       "        0.29324969,  0.13007539,  0.48767539,  0.17361885,  0.54867902,\n",
       "        0.74040741,  0.21790593,  0.08528901,  0.27221044,  0.19065935,\n",
       "        0.73234752,  0.7443194 ,  0.69555902,  0.82621074,  0.47629831,\n",
       "        0.62090877,  0.78992283,  0.20497415,  0.50744244,  0.77526792,\n",
       "        0.15994615,  0.54867365,  0.47687359,  0.44223726,  0.08126051,\n",
       "        0.48441609,  0.51592898,  0.26116063,  0.40255081,  0.85337301,\n",
       "        0.11988658,  0.57289121,  0.75693742,  0.31274596,  0.21420386,\n",
       "        0.10102415,  0.69395434,  0.06501461,  0.38367504,  0.7037484 ,\n",
       "        0.61420634,  0.34330456,  0.3219751 ,  0.40993552,  0.13111207,\n",
       "        0.42114779,  0.11710526,  0.58439686,  0.08932494,  0.71813544,\n",
       "        0.66848007,  0.12086153,  0.30089852,  0.15278756,  0.20314642,\n",
       "        0.34511666,  0.22272961,  0.21345354,  0.21714979,  0.279043  ,\n",
       "        0.63666678,  0.19624868,  0.12988532,  0.30914761,  0.31057195,\n",
       "        0.75963317,  0.73860246,  0.35798024,  0.18789727,  0.18202587,\n",
       "        0.13818939,  0.30187774,  0.05248885,  0.71976414,  0.54134875,\n",
       "        0.46686151,  0.4885072 ,  0.19482133,  0.65373956,  0.16880303,\n",
       "        0.54088859,  0.09757875,  0.70188109,  0.47861685,  0.56422153,\n",
       "        0.24711804,  0.32352421,  0.61065134,  0.15667062,  0.42695676,\n",
       "        0.1808685 ,  0.33863287,  0.15054259,  0.6094075 ,  0.24653156,\n",
       "        0.33800024,  0.6548627 ,  0.31081054,  0.14910573,  0.75424638,\n",
       "        0.15042425,  0.27208852,  0.28434319,  0.13974311,  0.35636403,\n",
       "        0.44028492,  0.23786247,  0.77233021,  0.95788095,  0.50017724,\n",
       "        0.67458143,  0.80271154,  0.19519312,  0.44970402,  0.68549119,\n",
       "        0.20081632,  0.25278834,  0.73536479,  0.68779317,  0.05453986,\n",
       "        0.16410414,  0.1193781 ,  0.27881117,  0.50430577,  0.21793406,\n",
       "        0.31630796,  0.18334758,  0.08080018,  0.36299373,  0.66773461,\n",
       "        0.17516393,  0.49622774,  0.34798374,  0.25021099,  0.06672059,\n",
       "        0.40213469,  0.40200673,  0.60348305,  0.68328333,  0.22476015,\n",
       "        0.69338423,  0.64375106,  0.25905142,  0.07131753,  0.19702984,\n",
       "        0.76523185,  0.11033504,  0.31502081,  0.70383843,  0.59155926,\n",
       "        0.61383506,  0.24683615,  0.41243201,  0.57152616,  0.60686987,\n",
       "        0.13330258,  0.37726632,  0.33670866,  0.30873012,  0.28685427,\n",
       "        0.54674233,  0.48674198,  0.43767977,  0.5381034 ,  0.51625533,\n",
       "        0.14947719,  0.10395801,  0.20434473,  0.7374129 ,  0.40675655,\n",
       "        0.16316457,  0.16996115,  0.90312532,  0.31706849,  0.12449109,\n",
       "        0.12319802,  0.02128069,  0.16960785,  0.28137087,  0.62976059,\n",
       "        0.26403788,  0.15565983,  0.34748729,  0.36280261,  0.59654745,\n",
       "        0.15705786,  0.18830145,  0.22077978,  0.82739411,  0.55609526,\n",
       "        0.32480369,  0.25804055,  0.23454375,  0.19112719,  0.62937256,\n",
       "        0.18445618,  0.70797561,  0.3765201 ,  0.35424268,  0.8094246 ,\n",
       "        0.5394526 ,  0.18531332,  0.17351282,  0.21343449,  0.19045995,\n",
       "        0.7962885 ,  0.5437978 ,  0.31712323,  0.29328404,  0.27176756,\n",
       "        0.15805584,  0.11232142,  0.3091951 ,  0.45337302,  0.38708977,\n",
       "        0.51717236,  0.19554397,  0.29135048,  0.3629642 ,  0.74741301,\n",
       "        0.18130629,  0.1065895 ,  0.5346842 ,  0.20580083,  0.26147726,\n",
       "        0.32323573,  0.67374519,  0.22115909,  0.40416309,  0.25948484,\n",
       "        0.21390569,  0.01407039,  0.64933259,  0.16272938,  0.24791634,\n",
       "        0.65955829,  0.2146619 ,  0.42442351,  0.18842051,  0.14713483,\n",
       "        0.50816955,  0.35805948,  0.22756359,  0.09728542,  0.29624655,\n",
       "        0.16721172,  0.50344031,  0.28449487,  0.09845306,  0.33375953,\n",
       "        0.4488937 ,  0.28772386,  0.6880432 ,  0.6169881 ,  0.38860786,\n",
       "        0.19195702,  0.14536462,  0.53224017,  0.22538416,  0.26593207,\n",
       "        0.42753755,  0.57820979,  0.79186678,  0.82565142,  0.18183448,\n",
       "        0.3563064 ,  0.75700017,  0.61476697,  0.08602269,  0.72865204,\n",
       "        0.20464724,  0.36757807,  0.62854722,  0.25024402,  0.33827851,\n",
       "        0.19665601,  0.21141965,  0.56454383,  0.59002536,  0.32270276,\n",
       "        0.27797826,  0.57425944,  0.72491471,  0.09087351,  0.13978905,\n",
       "        0.17668893,  0.01989268,  0.66625365])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 308)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred), len(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bbf4107cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.00485437,  0.00485437,  0.00970874,\n",
       "        0.00970874,  0.01456311,  0.01456311,  0.01941748,  0.01941748,\n",
       "        0.02427184,  0.02427184,  0.02912621,  0.02912621,  0.03883495,\n",
       "        0.03883495,  0.04368932,  0.04368932,  0.04854369,  0.04854369,\n",
       "        0.0631068 ,  0.0631068 ,  0.07281553,  0.07281553,  0.0776699 ,\n",
       "        0.0776699 ,  0.09223301,  0.09223301,  0.09708738,  0.09708738,\n",
       "        0.11165049,  0.11165049,  0.12135922,  0.12135922,  0.12621359,\n",
       "        0.12621359,  0.17475728,  0.17475728,  0.2038835 ,  0.2038835 ,\n",
       "        0.20873786,  0.20873786,  0.22330097,  0.22330097,  0.22815534,\n",
       "        0.22815534,  0.24271845,  0.24271845,  0.27184466,  0.27184466,\n",
       "        0.2815534 ,  0.2815534 ,  0.28640777,  0.28640777,  0.30097087,\n",
       "        0.30097087,  0.31553398,  0.31553398,  0.33009709,  0.33009709,\n",
       "        0.3592233 ,  0.3592233 ,  0.37378641,  0.37378641,  0.39320388,\n",
       "        0.39320388,  0.42718447,  0.42718447,  0.43203883,  0.43203883,\n",
       "        0.44660194,  0.44660194,  0.49029126,  0.49029126,  0.51456311,\n",
       "        0.51456311,  0.51941748,  0.51941748,  0.58737864,  0.58737864,\n",
       "        0.60679612,  0.60679612,  0.63592233,  0.63592233,  0.69902913,\n",
       "        0.69902913,  0.76213592,  0.76213592,  0.7815534 ,  0.7815534 ,\n",
       "        0.79126214,  0.79126214,  1.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This ROC curve provides a nice visual way to assess your classifier's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC[Area Under the ROC] computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8268608414239483\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_auc = cross_val_score(logreg, X, y, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC scores computed using 5-fold cross-validation: [ 0.7987037   0.80759259  0.81944444  0.86622642  0.85056604]\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246623733333333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.80219561, 0.80845051, 0.863341])/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longer area under dthe ROC curve  = better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-05,   8.48343e-05,   7.19686e-04,   6.10540e-03,\n",
       "         5.17947e-02,   4.39397e-01,   3.72759e+00,   3.16228e+01,\n",
       "         2.68270e+02,   2.27585e+03,   1.93070e+04,   1.63789e+05,\n",
       "         1.38950e+06,   1.17877e+07,   1.00000e+08])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it to the data\n",
    "logreg_cv.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 3.7275937203149381}\n"
     ]
    }
   ],
   "source": [
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.775974025974026\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space and dealing with multiple hyperparameters. A solution to this is to use RandomizedSearchCV, in which not all hyperparameter values are tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'max_depth': [3, None], 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BBF4329320>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BBF4329F60>, 'criterion': ['gini', 'entropy']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it to the data\n",
    "tree_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 5, 'min_samples_leaf': 7}\n"
     ]
    }
   ],
   "source": [
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.734375\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out set in practice I: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-05,   8.48343e-05,   7.19686e-04,   6.10540e-03,\n",
       "         5.17947e-02,   4.39397e-01,   3.72759e+00,   3.16228e+01,\n",
       "         2.68270e+02,   2.27585e+03,   1.93070e+04,   1.63789e+05,\n",
       "         1.38950e+06,   1.17877e+07,   1.00000e+08]), 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 31.622776601683793, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Accuracy: 0.7673913043478261\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Hold-out set in practice II: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember lasso and ridge regression from the previous chapter? Lasso used the L1 penalty to regularize, while ridge used the L2 penalty. There is another type of regularized regression known as the elastic net. In elastic net regularization, the penalty term is a linear combination of the L1 and L2 penalties:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a∗L1+b∗L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
